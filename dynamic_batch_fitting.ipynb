{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d873539d",
   "metadata": {},
   "source": [
    "# Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71c1784f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ee7e99927e64832aa02e85bce6e6332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Physics-aware fitting:   0%|          | 0/260 [00:00<?, ?file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Rows: 260\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Physics-aware dynamic batch EIS fitter (TL)\n",
    "# Rs + (Rp || CPE) + TL   —   Nanoporous gold in H2SO4\n",
    "# Option B rewrite: length-agnostic per-file allocations + pandas future-proofing\n",
    "# ============================================\n",
    "\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, math, os, re, traceback\n",
    "from scipy.optimize import least_squares\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ------------------------- User knobs -------------------------\n",
    "ROOT_DIR   = Path(\"/Users/hosseinostovar/Desktop/BACKUP/Data_H2SO4_NPG/data/NPG-500mM-H2SO4-whole_three\")\n",
    "FILE_GLOB  = \"EIS_whole_spectrum_*_H2SO4_*C_*kHz_0.1Hz_pH=*.csv\"\n",
    "\n",
    "SHOW_PLOTS    = False\n",
    "SAVE_FIG      = True\n",
    "SAVE_CSV      = True\n",
    "TARGET_RMSE   = 0.5\n",
    "MAX_RETRIES   = 8\n",
    "JITTER_SCALE  = 0.28\n",
    "RNG_SEED      = 123\n",
    "FREQ_UNIT_HINT= \"auto\"  # \"auto\",\"hz\",\"khz\",\"mhz\"\n",
    "\n",
    "# ----- Physics-aware controls -----\n",
    "PRIOR_STRENGTH_MIN  = 0.01\n",
    "PRIOR_STRENGTH_MAX  = 0.20\n",
    "PRIOR_STRENGTH_STEP = 0.05\n",
    "PRIOR_STRENGTH_MAX_HARD = 0.40   # absolute maximum clamp\n",
    "\n",
    "NARROWING_FACTOR_DECADES = 0.6    # ± decades around prior center for log-params\n",
    "NEIGHBOR_WINDOW = 3               # use up to last K concentration groups\n",
    "TREND_PENALTY_LAMBDA = 0.10       # score = RMSE + λ * PhysicsRMS\n",
    "\n",
    "# Minimum span floors after narrowing (transform space)\n",
    "MIN_SPAN_LOG   = 0.40  # ~±0.20 ln (≈ ±22%)\n",
    "MIN_SPAN_LOGIT = 0.35  # for n0/n1; Δn ≈ 0.05–0.08 near 0.7–0.9\n",
    "MIN_NEIGHBORS  = 2     # need this many to start narrowing\n",
    "\n",
    "# --------------------- Helper: hyper-parameter grid ---------------------\n",
    "def build_hyper_grid():\n",
    "    # prior_strength values: include 0.01, then 0.05..0.20 in 0.05 steps\n",
    "    vals = [PRIOR_STRENGTH_MIN]\n",
    "    s = PRIOR_STRENGTH_STEP\n",
    "    x = 0.05\n",
    "    while x <= PRIOR_STRENGTH_MAX + 1e-12:\n",
    "        if x not in vals:\n",
    "            vals.append(round(x, 2))\n",
    "        x += s\n",
    "    # Cartesian product over robust, weight_hf, prior_strength\n",
    "    grid = []\n",
    "    for robust in (True, False):\n",
    "        for weight_hf in (True, False):\n",
    "            for ps in vals:\n",
    "                grid.append(dict(robust=robust, weight_hf=weight_hf, prior_strength=ps))\n",
    "    return grid\n",
    "\n",
    "# ------------------------- Flexible CSV reader -------------------------\n",
    "def _find_column(cols, *cands):\n",
    "    cl = [c.lower() for c in cols]\n",
    "    for cand in cands:\n",
    "        for i, c in enumerate(cl):\n",
    "            if cand in c:\n",
    "                return cols[i]\n",
    "    return None\n",
    "\n",
    "def _apply_freq_unit(freq, header_lower, unit_hint=\"auto\"):\n",
    "    if unit_hint and unit_hint.lower() in {\"hz\", \"khz\", \"mhz\"}:\n",
    "        u = unit_hint.lower()\n",
    "        if u == \"khz\": return freq * 1e3\n",
    "        if u == \"mhz\": return freq * 1e6\n",
    "        return freq\n",
    "    if \"khz\" in header_lower: return freq * 1e3\n",
    "    if \"mhz\" in header_lower: return freq * 1e6\n",
    "    return freq\n",
    "\n",
    "def load_impedance_csv(path, freq_unit_hint=FREQ_UNIT_HINT):\n",
    "    df = pd.read_csv(path)\n",
    "    cols = list(df.columns)\n",
    "\n",
    "    fcol = _find_column(cols, \"frequency\", \"freq\", \"hz\", \"khz\", \"mhz\")\n",
    "    if fcol is None:\n",
    "        raise ValueError(\"No frequency column found\")\n",
    "    # pandas future-proof: pass dtype via keyword; avoid positional\n",
    "    freq = df[fcol].to_numpy(dtype=float)\n",
    "    freq = _apply_freq_unit(freq, fcol.lower(), unit_hint=freq_unit_hint)\n",
    "\n",
    "    zrcol = None\n",
    "    for key in [\"we.z'\", \"z' (\", \"z real\", \"zreal\"]:\n",
    "        zrcol = _find_column(cols, key)\n",
    "        if zrcol: break\n",
    "    if zrcol is None: \n",
    "        raise ValueError(\"No Z' (real) column found\")\n",
    "    Zr = df[zrcol].to_numpy(dtype=float)\n",
    "\n",
    "    zim_neg = _find_column(cols, \"-z\\\"\", \"-z''\", \"we.-z\\\"\")\n",
    "    zim_pos = _find_column(cols, \"z\\\"\", \"z''\")\n",
    "    if zim_neg is not None:\n",
    "        Zi = -df[zim_neg].to_numpy(dtype=float)\n",
    "    elif zim_pos is not None:\n",
    "        Zi = -df[zim_pos].to_numpy(dtype=float)\n",
    "    else:\n",
    "        zim = _find_column(cols, \"imag\")\n",
    "        if zim is None: \n",
    "            raise ValueError(\"No imaginary part column found\")\n",
    "        # Some exports store +Imag; model expects Nyquist with -Imag\n",
    "        Zi = df[zim].to_numpy(dtype=float)\n",
    "    Z = Zr + 1j*Zi\n",
    "    return freq, Z\n",
    "\n",
    "# -------------------------- Circuit elements --------------------------\n",
    "def coth(x):\n",
    "    t = np.tanh(x)\n",
    "    out = np.empty_like(t, dtype=complex)\n",
    "    small = np.abs(t) < 1e-12\n",
    "    out[~small] = 1.0 / t[~small]\n",
    "    xs = x[small]\n",
    "    out[small] = 1.0/np.where(xs==0, 1e-30, xs) + xs/3.0\n",
    "    return out\n",
    "\n",
    "def zarc(Rp, Y0, n, w):\n",
    "    return 1.0 / (1.0/Rp + Y0*(1j*w)**n) if Rp>0 else np.zeros_like(w, dtype=complex)\n",
    "\n",
    "def tl_impedance(r, y0, n, L, w):\n",
    "    gamma = np.sqrt(r*y0*(1j*w)**n)\n",
    "    Z0 = np.sqrt(r/(y0*(1j*w)**n))\n",
    "    return Z0 * coth(L*gamma)\n",
    "\n",
    "# -------------------------- Transforms --------------------------\n",
    "def _logit(x):      return np.log(x/(1.0-x))\n",
    "def _invlogit(t):   return 1.0/(1.0+np.exp(-t))\n",
    "\n",
    "# -------------------------- Physical safety bounds --------------------------\n",
    "PHYS_BOUNDS_TL = {\n",
    "    \"Rs_min\": 1e-3,  \"Rs_max\": 1e5,\n",
    "    \"Rp_min\": 1e-2,  \"Rp_max\": 1e7,\n",
    "\n",
    "    \"Y0_min\": 1e-8,  \"Y0_max\": 1e-2,\n",
    "    \"n0_min\": 0.55,  \"n0_max\": 0.97,\n",
    "\n",
    "    \"r_min\":  1e4,   \"r_max\": 1e8,    # Ω/m\n",
    "    \"y0_min\": 1e-3,  \"y0_max\": 1e3,   # Ω^-1 s^n1 / m\n",
    "    \"n1_min\": 0.60,  \"n1_max\": 0.97,\n",
    "\n",
    "    \"L_min\":  1e-7,  \"L_max\": 3e-4,   # meters\n",
    "}\n",
    "\n",
    "def _bounds_TL():\n",
    "    b = PHYS_BOUNDS_TL\n",
    "    lb = np.array([\n",
    "        np.log(b[\"Rs_min\"]), np.log(b[\"Rp_min\"]), np.log(b[\"Y0_min\"]),\n",
    "        _logit(b[\"n0_min\"]),\n",
    "        np.log(b[\"r_min\"]),  np.log(b[\"y0_min\"]),\n",
    "        _logit(b[\"n1_min\"]),\n",
    "        np.log(b[\"L_min\"])\n",
    "    ], float)\n",
    "    ub = np.array([\n",
    "        np.log(b[\"Rs_max\"]), np.log(b[\"Rp_max\"]), np.log(b[\"Y0_max\"]),\n",
    "        _logit(b[\"n0_max\"]),\n",
    "        np.log(b[\"r_max\"]),  np.log(b[\"y0_max\"]),\n",
    "        _logit(b[\"n1_max\"]),\n",
    "        np.log(b[\"L_max\"])\n",
    "    ], float)\n",
    "    return lb, ub\n",
    "\n",
    "# -------------------------- Model in transform space --------------------------\n",
    "def model_TL(p, w):\n",
    "    # p = [log_Rs, log_Rp, log_Y0, n0_logit, log_r, log_y0, n1_logit, log_L]\n",
    "    Rs, Rp, Y0, n0 = np.exp(p[0]), np.exp(p[1]), np.exp(p[2]), _invlogit(p[3])\n",
    "    r, y0, n1, L   = np.exp(p[4]), np.exp(p[5]), _invlogit(p[6]), np.exp(p[7])\n",
    "    return Rs + zarc(Rp, Y0, n0, w) + tl_impedance(r, y0, n1, L, w)\n",
    "\n",
    "# -------------------------- Initial guess --------------------------\n",
    "def initial_guess(freq, Z):\n",
    "    idx = np.argsort(freq)[::-1]; f = freq[idx]; Zs = Z[idx]\n",
    "    hi_n = max(3, len(Zs)//20)\n",
    "    Rs0 = np.percentile(Zs.real[:hi_n], 10)\n",
    "    kmax = int(np.argmax(-Zs.imag)) if Zs.size else None\n",
    "    fpk = f[kmax] if (kmax is not None and 0 <= kmax < f.size) else (np.median(f) if f.size else 1.0)\n",
    "    n0, Rp0 = 0.8, max(np.percentile(Zs.real,90)-Rs0, 1.0)\n",
    "    Y00 = 1.0/(Rp0*(2*np.pi*max(fpk,1e-9))**n0)\n",
    "    r0 = max((np.max(Zs.real)-np.min(Zs.real))/50.0, 1.0)\n",
    "    y0, n1 = 1e-2, 0.85\n",
    "    wmin = 2*np.pi*max(min(f) if f.size else 1.0, 1e-3)\n",
    "    L0 = 1.0/np.sqrt(max(r0*y0*(wmin**n1), 1e-12))\n",
    "    p0 = np.array([\n",
    "        np.log(max(Rs0,1e-3)), np.log(max(Rp0,1e-2)), np.log(max(Y00,1e-9)),\n",
    "        math.log(n0/(1-n0)),\n",
    "        np.log(max(r0,1e0)),   np.log(max(y0,1e-8)),\n",
    "        math.log(n1/(1-n1)),\n",
    "        np.log(max(L0,1e-8))\n",
    "    ], float)\n",
    "    # clip to physical bounds (coarse)\n",
    "    ph_lb, ph_ub = _bounds_TL(); eps=1e-12\n",
    "    return np.clip(p0, ph_lb+eps, ph_ub-eps)\n",
    "\n",
    "# -------------------------- Physics expectations --------------------------\n",
    "# name: (index in p, monotone vs C, monotone vs T, transform type)\n",
    "EXPECT = {\n",
    "    \"Rs\":        (0, -1, -1, \"log\"),\n",
    "    \"Rp\":        (1, -1, -1, \"log\"),\n",
    "    \"Y0_ZARC\":   (2, +1, +1, \"log\"),\n",
    "    \"n0\":        (3,  0,  0, \"logit\"),\n",
    "    \"r_line\":    (4, -1, -1, \"log\"),\n",
    "    \"y0_line\":   (5, +1, +1, \"log\"),\n",
    "    \"n1\":        (6,  0,  0, \"logit\"),\n",
    "    \"L\":         (7,  0,  0, \"log\"),\n",
    "}\n",
    "\n",
    "# -------------------------- Dynamic priors --------------------------\n",
    "def build_dynamic_priors(prev_df, C, T, p_names):\n",
    "    \"\"\"\n",
    "    Build prior centers/sigmas from neighbors (<= C, last NEIGHBOR_WINDOW concentrations; weight by ΔC & ΔT).\n",
    "    Returns dict: name -> {mu, sigma, type}.\n",
    "    \"\"\"\n",
    "    priors = {}\n",
    "    if prev_df is None or prev_df.empty:\n",
    "        return priors\n",
    "\n",
    "    cand = prev_df[prev_df[\"C\"] <= C].copy()\n",
    "    if cand.empty:\n",
    "        return priors\n",
    "\n",
    "    uniqC = sorted(cand[\"C\"].unique())\n",
    "    useC = uniqC[-min(NEIGHBOR_WINDOW, len(uniqC)):]\n",
    "    cand = cand[cand[\"C\"].isin(useC)].copy()\n",
    "    if cand.empty:\n",
    "        return priors\n",
    "\n",
    "    cand[\"w\"] = 1.0 / (1.0 + (C - cand[\"C\"]).abs() + 0.3*(T - cand[\"T\"]).abs())\n",
    "\n",
    "    for name in p_names:\n",
    "        if name not in cand.columns: \n",
    "            continue\n",
    "        s = cand[[name, \"w\"]].dropna()\n",
    "        if s.empty: \n",
    "            continue\n",
    "        # weighted-median-ish via repetition\n",
    "        rep = np.repeat(s[name].values, np.clip((s[\"w\"]*5).round().astype(int),1,10))\n",
    "        mu = float(np.median(rep)) if rep.size>0 else float(s[name].median())\n",
    "\n",
    "        # log/logit sigma estimates\n",
    "        if EXPECT[name][3] == \"log\":\n",
    "            sigma_ln = NARROWING_FACTOR_DECADES * np.log(10.0)\n",
    "            priors[name] = dict(mu=mu, sigma=sigma_ln, type=\"log\")\n",
    "        else:  # logit\n",
    "            mu_clip = min(max(mu, 0.05), 0.95)\n",
    "            band = 0.07  # ~Δn\n",
    "            t0 = _logit(min(max(mu_clip, 1e-6), 1-1e-6))\n",
    "            t1 = _logit(min(max(mu_clip+band, 1e-6), 1-1e-6))\n",
    "            priors[name] = dict(mu=mu_clip, sigma=abs(t1-t0), type=\"logit\")\n",
    "\n",
    "    # Optional: tighten n1 a touch\n",
    "    if priors.get(\"n1\") and priors[\"n1\"][\"type\"] == \"logit\":\n",
    "        priors[\"n1\"][\"sigma\"] = max(0.25, min(priors[\"n1\"][\"sigma\"], 0.35))\n",
    "\n",
    "    return priors\n",
    "\n",
    "def dynamic_bounds_from_priors(base_bounds, priors, neighbor_count: int = 0):\n",
    "    \"\"\"\n",
    "    Intersect physical bounds with a narrowed window around prior centers.\n",
    "    Keep a minimum width so x0 is always feasible.\n",
    "    Only narrow if neighbor_count >= MIN_NEIGHBORS.\n",
    "    \"\"\"\n",
    "    lb, ub = base_bounds\n",
    "    lb = lb.copy(); ub = ub.copy()\n",
    "\n",
    "    if neighbor_count < MIN_NEIGHBORS or not priors:\n",
    "        return lb, ub\n",
    "\n",
    "    for name, (idx, _sC, _sT, typ) in EXPECT.items():\n",
    "        if name not in priors:\n",
    "            continue\n",
    "        pr = priors[name]\n",
    "        if typ == \"log\":\n",
    "            mu_log = np.log(max(pr[\"mu\"], 1e-300))\n",
    "            span   = max(pr.get(\"sigma\", 0.0), MIN_SPAN_LOG)\n",
    "            cand_lb, cand_ub = mu_log - span, mu_log + span\n",
    "        else:\n",
    "            mu_t   = _logit(min(max(pr[\"mu\"], 1e-9), 1-1e-9))\n",
    "            span_t = max(pr.get(\"sigma\", 0.0), MIN_SPAN_LOGIT)\n",
    "            cand_lb, cand_ub = mu_t - span_t, mu_t + span_t\n",
    "\n",
    "        lb[idx] = max(lb[idx], cand_lb)\n",
    "        ub[idx] = min(ub[idx], cand_ub)\n",
    "\n",
    "    eps = 1e-12\n",
    "    for i in range(len(lb)):\n",
    "        if not np.isfinite(lb[i]) or not np.isfinite(ub[i]):\n",
    "            lb[i] = base_bounds[0][i]\n",
    "            ub[i] = base_bounds[1][i]\n",
    "        if ub[i] - lb[i] < eps:\n",
    "            mid = 0.5*(ub[i]+lb[i])\n",
    "            span = max(MIN_SPAN_LOG, MIN_SPAN_LOGIT)\n",
    "            lb[i] = mid - 0.5*span\n",
    "            ub[i] = mid + 0.5*span\n",
    "    return lb, ub\n",
    "\n",
    "def physics_prior_residual(p, C, T, priors, prior_strength):\n",
    "    \"\"\"\n",
    "    Fixed-length physics residuals:\n",
    "      - Anchors: one per parameter that has a prior (Gaussian in transform space)\n",
    "      - Monotonic vs C: one per parameter with signC!=0 AND a prior; value is\n",
    "        relu((wrong - tol)/tol) so it's zero if within tolerance.\n",
    "      -> Length is constant for a given file+prior set.\n",
    "    Returns (residual_vector, residual_rms)\n",
    "    \"\"\"\n",
    "    res = []\n",
    "\n",
    "    # 1) Anchors (always one per param that has a prior)\n",
    "    for name, (idx, _signC, _signT, typ) in EXPECT.items():\n",
    "        if name not in priors:\n",
    "            continue\n",
    "        if typ == \"log\":\n",
    "            val_log = p[idx]\n",
    "            mu_log  = np.log(max(priors[name][\"mu\"], 1e-300))\n",
    "            s_ln    = max(priors[name][\"sigma\"], 1e-9)\n",
    "            res.append( prior_strength * ((val_log - mu_log) / s_ln) )\n",
    "        else:\n",
    "            val_t = p[idx]\n",
    "            mu_t  = _logit(min(max(priors[name][\"mu\"], 1e-9), 1-1e-9))\n",
    "            s_t   = max(priors[name][\"sigma\"], 1e-6)\n",
    "            res.append( prior_strength * ((val_t - mu_t) / s_t) )\n",
    "\n",
    "    # 2) One-sided monotonic nudges vs C (always present, zero when satisfied)\n",
    "    for name, (idx, signC, _signT, typ) in EXPECT.items():\n",
    "        if signC == 0 or name not in priors:\n",
    "            continue\n",
    "        val = p[idx]\n",
    "        if typ == \"log\":\n",
    "            mu = np.log(max(priors[name][\"mu\"], 1e-300)); tol = 0.5   # ~half ln-decade\n",
    "        else:\n",
    "            mu = _logit(min(max(priors[name][\"mu\"], 1e-9), 1-1e-9)); tol = 0.25\n",
    "\n",
    "        wrong = (val - mu) * np.sign(signC)  # >0 means moving the wrong way\n",
    "        # relu but always include one residual per param\n",
    "        mono = max(0.0, (wrong - tol) / max(tol, 1e-12))\n",
    "        res.append( prior_strength * mono )\n",
    "\n",
    "    r = np.array(res, dtype=float) if res else np.zeros(0, dtype=float)\n",
    "    rms = float(np.sqrt(np.mean(r**2))) if r.size else 0.0\n",
    "    return r, rms\n",
    "\n",
    "\n",
    "# -------------------------- Residual (data + physics) --------------------------\n",
    "def residual_total(p, w, Zexp, weights, C, T, priors, prior_strength):\n",
    "    \"\"\"\n",
    "    Length-agnostic residual builder: all per-file allocations are derived from len(w).\n",
    "    \"\"\"\n",
    "    Zm = model_TL(p, w)\n",
    "    # data residuals (size 2*N)\n",
    "    r_re = (Zm.real - Zexp.real)\n",
    "    r_im = (Zm.imag - Zexp.imag)\n",
    "    if weights is not None:\n",
    "        # allocate per-file weight vector of size 2*N\n",
    "        w2 = np.concatenate([weights, weights])\n",
    "        r = np.concatenate([r_re, r_im]) * w2\n",
    "    else:\n",
    "        r = np.concatenate([r_re, r_im])\n",
    "\n",
    "    # physics residuals (variable length)\n",
    "    r_phys, _ = physics_prior_residual(p, C, T, priors, prior_strength)\n",
    "    # single concat (length-agnostic)\n",
    "    return np.concatenate([r, r_phys]) if r_phys.size else r\n",
    "\n",
    "# -------------------------- Solve one spectrum --------------------------\n",
    "def solve_one(freq, Z, C, T, rng, cfg, dyn_lb, dyn_ub,\n",
    "              target_rmse=TARGET_RMSE, max_retries=MAX_RETRIES, jitter_scale=JITTER_SCALE):\n",
    "    # sort ascending by f for evaluation; all per-file\n",
    "    order = np.argsort(freq)\n",
    "    freq = freq[order]; Z = Z[order]\n",
    "    w = 2*np.pi*freq\n",
    "    N = w.size\n",
    "\n",
    "    # weights (length N) — allocate per file\n",
    "    weights = None\n",
    "    if cfg[\"weight_hf\"]:\n",
    "        mag = np.abs(Z)\n",
    "        floor = np.percentile(mag, 5)\n",
    "        weights = 1.0 / np.maximum(mag, floor)\n",
    "\n",
    "    priors = cfg.get(\"_priors_\", {})\n",
    "    prior_strength = float(np.clip(cfg[\"prior_strength\"], PRIOR_STRENGTH_MIN, PRIOR_STRENGTH_MAX_HARD))\n",
    "\n",
    "    # initial guess clipped into (dynamic) bounds\n",
    "    p_best = initial_guess(freq, Z)\n",
    "    eps = 1e-12\n",
    "    p0 = np.clip(p_best, dyn_lb+eps, dyn_ub-eps)\n",
    "\n",
    "    def _solve(p0_local):\n",
    "        res = least_squares(\n",
    "            residual_total, p0_local,\n",
    "            args=(w, Z, weights, C, T, priors, prior_strength),\n",
    "            loss=(\"soft_l1\" if cfg[\"robust\"] else \"linear\"),\n",
    "            max_nfev=20000, bounds=(dyn_lb, dyn_ub)\n",
    "        )\n",
    "        Zfit = model_TL(res.x, w)\n",
    "\n",
    "        # compute data RMSE in a length-agnostic way\n",
    "        d_re = (Zfit.real - Z.real)\n",
    "        d_im = (Zfit.imag - Z.imag)\n",
    "        if weights is not None:\n",
    "            d = np.concatenate([d_re, d_im]) * np.concatenate([weights, weights])\n",
    "        else:\n",
    "            d = np.concatenate([d_re, d_im])\n",
    "        rmse = float(np.sqrt(np.mean(d**2)))\n",
    "\n",
    "        _, phys_rms = physics_prior_residual(res.x, C, T, priors, prior_strength)\n",
    "        score = rmse + TREND_PENALTY_LAMBDA*phys_rms\n",
    "        return dict(res=res, Zfit=Zfit, rmse=rmse, phys_rms=phys_rms, score=score)\n",
    "\n",
    "    # First attempt (with safety fallback)\n",
    "    try:\n",
    "        best = _solve(p0)\n",
    "    except ValueError as e:\n",
    "        if \"`x0` is infeasible\" in str(e):\n",
    "            p_mid = 0.5*(dyn_lb + dyn_ub)\n",
    "            best = _solve(p_mid)\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    # Retry loop with jitter (respect bounds)\n",
    "    tries = 0\n",
    "    exp_idx = np.array([0,1,2,4,5,7], dtype=int)\n",
    "    logit_idx = np.array([3,6], dtype=int)\n",
    "    while best[\"rmse\"] > target_rmse and tries < max_retries:\n",
    "        tries += 1\n",
    "        mult = np.exp(rng.normal(0.0, jitter_scale, size=exp_idx.size))\n",
    "        p_try = best[\"res\"].x.copy()\n",
    "        p_try[exp_idx] += np.log(mult)\n",
    "        p_try[logit_idx] += rng.normal(0.0, jitter_scale, size=logit_idx.size)\n",
    "        p_try = np.clip(p_try, dyn_lb+eps, dyn_ub-eps)\n",
    "        cand = _solve(p_try)\n",
    "        if cand[\"score\"] < best[\"score\"]:\n",
    "            best = cand\n",
    "\n",
    "    return best\n",
    "\n",
    "# -------------------------- Ordering by C then T --------------------------\n",
    "def parse_C_T_from_path(path: Path):\n",
    "    s = str(path)\n",
    "    C = None; T = None\n",
    "    # Prefer folder names\n",
    "    for part in path.parts:\n",
    "        mC = re.search(r\"(\\d+(?:\\.\\d+)?)\\s*mM\", part, flags=re.IGNORECASE)\n",
    "        if mC: C = float(mC.group(1))\n",
    "        mT = re.search(r\"(\\d+(?:\\.\\d+)?)\\s*C\", part, flags=re.IGNORECASE)\n",
    "        if mT: T = float(mT.group(1))\n",
    "    # Fallback to filename\n",
    "    if C is None:\n",
    "        mC = re.search(r\"(\\d+(?:\\.\\d+)?)\\s*mM\", path.name, flags=re.IGNORECASE)\n",
    "        if mC: C = float(mC.group(1))\n",
    "    if T is None:\n",
    "        mT = re.search(r\"(\\d+(?:\\.\\d+)?)\\s*C\", path.name, flags=re.IGNORECASE)\n",
    "        if mT: T = float(mT.group(1))\n",
    "    return C, T\n",
    "\n",
    "def list_files_ordered(root: Path, glob: str):\n",
    "    files = sorted(root.rglob(glob))\n",
    "    rows = []\n",
    "    for f in files:\n",
    "        C, T = parse_C_T_from_path(f)\n",
    "        if C is None or T is None:\n",
    "            continue\n",
    "        rows.append((C, T, f))\n",
    "    rows.sort(key=lambda x: (x[0], x[1]))  # numeric sort: C then T\n",
    "    return rows\n",
    "\n",
    "# -------------------------- Batch runner --------------------------\n",
    "def batch_fit_physics_aware(root_dir: Path = ROOT_DIR, file_glob: str = FILE_GLOB):\n",
    "    results = []\n",
    "    rng = np.random.default_rng(RNG_SEED)\n",
    "    prev_df = pd.DataFrame(columns=[\"C\",\"T\",\"Rs\",\"Rp\",\"Y0_ZARC\",\"n0\",\"r_line\",\"y0_line\",\"n1\",\"L\"])\n",
    "\n",
    "    files = list_files_ordered(root_dir, file_glob)\n",
    "    if not files:\n",
    "        print(f\"[warn] no files matching {file_glob} under {root_dir}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    base_lb, base_ub = _bounds_TL()\n",
    "    HYPER_GRID = build_hyper_grid()\n",
    "\n",
    "    for C, T, f in tqdm(files, desc=\"Physics-aware fitting\", unit=\"file\"):\n",
    "        try:\n",
    "            freq, Z = load_impedance_csv(str(f), freq_unit_hint=FREQ_UNIT_HINT)\n",
    "            # fully per-file masks/allocations\n",
    "            good = np.isfinite(freq) & np.isfinite(Z.real) & np.isfinite(Z.imag) & (freq>0)\n",
    "            freq, Z = freq[good], Z[good]\n",
    "            if freq.size < 5:\n",
    "                raise ValueError(\"Too few valid points\")\n",
    "\n",
    "            # Build priors & dynamic bounds\n",
    "            priors = build_dynamic_priors(prev_df, C, T, p_names=list(EXPECT.keys()))\n",
    "            neighbor_count = 0 if prev_df is None or prev_df.empty else len(prev_df[prev_df[\"C\"] <= C])\n",
    "            dyn_lb, dyn_ub = dynamic_bounds_from_priors((base_lb, base_ub), priors, neighbor_count)\n",
    "\n",
    "            # Order hyper-grid: for low C, try weight_hf=False combos earlier\n",
    "            grid = list(HYPER_GRID)\n",
    "            if C <= 5.0:\n",
    "                grid.sort(key=lambda g: (g[\"weight_hf\"], g[\"robust\"], g[\"prior_strength\"]))  # False first\n",
    "\n",
    "            best_overall = None; best_cfg = None\n",
    "            for cfg in grid:\n",
    "                cfg = cfg.copy()\n",
    "                cfg[\"_priors_\"] = priors\n",
    "                cfg[\"prior_strength\"] = float(np.clip(cfg[\"prior_strength\"], PRIOR_STRENGTH_MIN, PRIOR_STRENGTH_MAX_HARD))\n",
    "\n",
    "                res = solve_one(freq, Z, C, T, rng, cfg, dyn_lb, dyn_ub,\n",
    "                                target_rmse=TARGET_RMSE, max_retries=MAX_RETRIES, jitter_scale=JITTER_SCALE)\n",
    "                if (best_overall is None) or (res[\"score\"] < best_overall[\"score\"]):\n",
    "                    best_overall = res\n",
    "                    best_cfg = cfg\n",
    "\n",
    "            # Unpack best\n",
    "            p = best_overall[\"res\"].x\n",
    "            Rs, Rp, Y0, n0 = float(np.exp(p[0])), float(np.exp(p[1])), float(np.exp(p[2])), float(_invlogit(p[3]))\n",
    "            r, y0, n1, L   = float(np.exp(p[4])), float(np.exp(p[5])), float(_invlogit(p[6])), float(np.exp(p[7]))\n",
    "            Zfit           = best_overall[\"Zfit\"]\n",
    "            rmse           = best_overall[\"rmse\"]\n",
    "            phys_rms       = best_overall[\"phys_rms\"]\n",
    "\n",
    "            # Bound hits?\n",
    "            eps = 1e-9\n",
    "            hit_bounds = any(abs(p[i]-dyn_lb[i])<eps or abs(p[i]-dyn_ub[i])<eps for i in range(len(p)))\n",
    "\n",
    "            # Save outputs\n",
    "            out_dir = f.parent / \"fitting_TL\" / f.stem\n",
    "            out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            if SAVE_FIG or SHOW_PLOTS:\n",
    "                fig = plt.figure(figsize=(6,5))\n",
    "                plt.plot(Z.real, -Z.imag, 'o', ms=4, label=\"Data\")\n",
    "                plt.plot(Zfit.real, -Zfit.imag, '-', label=\"Fit\")\n",
    "                plt.xlabel(\"Z' (Ω)\"); plt.ylabel(\"-Z'' (Ω)\")\n",
    "                plt.title(f\"Nyquist: {f.name}\")\n",
    "                plt.legend(); plt.grid(True); plt.tight_layout()\n",
    "                if SAVE_FIG:\n",
    "                    fig.savefig(out_dir / \"nyquist_TL.png\", dpi=300)\n",
    "                if SHOW_PLOTS: plt.show()\n",
    "                else: plt.close(fig)\n",
    "\n",
    "            meta = {\n",
    "                \"File\": str(f),\n",
    "                \"C (mM)\": C, \"T (C)\": T,\n",
    "                \"Model\": \"Rs+(Rp||CPE)+TL\",\n",
    "                \"RMSE (Ω)\": rmse, \"PhysicsRMS\": phys_rms,\n",
    "                \"ROBUST\": best_cfg[\"robust\"], \"WEIGHT_HF\": best_cfg[\"weight_hf\"],\n",
    "                \"prior_strength\": best_cfg[\"prior_strength\"],\n",
    "                \"hit_bounds\": hit_bounds,\n",
    "                \"Rs (Ω)\": Rs, \"Rp (Ω)\": Rp,\n",
    "                \"Y0_ZARC (Ω^-1 s^n0)\": Y0, \"n0 (-)\": n0,\n",
    "                \"r_line (Ω/m)\": r, \"y0_line (Ω^-1 s^n1 / m)\": y0,\n",
    "                \"n1 (-)\": n1, \"L (m)\": L\n",
    "            }\n",
    "            results.append(meta)\n",
    "\n",
    "            if SAVE_CSV:\n",
    "                # per-file allocations for saving\n",
    "                order = np.argsort(freq)\n",
    "                df_fit = pd.DataFrame({\n",
    "                    \"Frequency (Hz)\": freq[order],\n",
    "                    \"Zreal_raw (Ω)\" : Z.real[order],\n",
    "                    \"-Zimag_raw (Ω)\": -Z.imag[order],\n",
    "                    \"Zreal_fit (Ω)\" : Zfit.real[order],\n",
    "                    \"-Zimag_fit (Ω)\": -Zfit.imag[order],\n",
    "                })\n",
    "                df_fit.to_csv(out_dir / \"raw_vs_fit_TL.csv\", index=False)\n",
    "                pd.DataFrame([meta]).to_csv(out_dir / \"params_TL.csv\", index=False)\n",
    "\n",
    "            # Update neighbors pool (guard concat-on-empty to avoid pandas future warnings)\n",
    "            tmp = pd.DataFrame([{\n",
    "                \"C\": C, \"T\": T,\n",
    "                \"Rs\": Rs, \"Rp\": Rp, \"Y0_ZARC\": Y0, \"n0\": n0,\n",
    "                \"r_line\": r, \"y0_line\": y0, \"n1\": n1, \"L\": L\n",
    "            }])\n",
    "            if prev_df.empty:\n",
    "                prev_df = tmp\n",
    "            else:\n",
    "                prev_df = pd.concat([prev_df, tmp], ignore_index=True)\n",
    "\n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"[error] {f.name}: {e}\")\n",
    "            traceback.print_exc(limit=1)\n",
    "\n",
    "    # Write summary (write directly to path; no intermediate string)\n",
    "    df_sum = pd.DataFrame(results)\n",
    "    if not df_sum.empty:\n",
    "        df_sum.to_csv(root_dir / \"summary_fitting_TL_physics.csv\", index=False)\n",
    "    return df_sum\n",
    "\n",
    "# -------------------------- Run --------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    summary = batch_fit_physics_aware(ROOT_DIR, FILE_GLOB)\n",
    "    print(\"Done. Rows:\", 0 if summary is None else len(summary))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
