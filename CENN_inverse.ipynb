{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51dad3b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27e256ea87c44c2f90bf404784f4fe12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sensitivity sweep (ranking):   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4280d594a6a74fd4b2146547c426ac30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calibration inverse @ top-1:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac1a016901234b9f93ea183084134f72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calibration inverse @ top-3:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afdef2a0d75942a09e137ce419896cd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calibration inverse @ top-6:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03a7a765488844eeab8a63d18281f907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calibration inverse @ top-10:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7a37ac7b34846deb23805e2af8d9f8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "TEST inverse @ top-1:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e359587351254421932ba35aae56138b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "TEST inverse @ top-3:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d5c697fbeeb4e0d86e6e3f0360b3248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "TEST inverse @ top-6:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4076ba6235e401fa4116804153e8b8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "TEST inverse @ top-10:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "944ecdc5666f4041a97aebe2be2857a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "TEST inverse @ top-3:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DONE ===\n",
      "Chosen frequency set (Hz): [1120.0386846932463, 1267.006317736862, 8053.13803910887]\n",
      "Calibration metrics: {'N': 166, 'C_MAE': 0.23179246465847766, 'T_MAE': 2.028279560927099, 'K': 3}\n",
      "Test metrics: {'C_MAE_mM': 0.3046269289635919, 'T_MAE_C': 2.5793108670117184}\n",
      "Artifacts saved in: /Users/hosseinostovar/Desktop/BACKUP/Data_H2SO4_NPG/data/single_frequency/Single_frequencies_whole_spectrum/inverse_reports/operando_piplines/high_f_1000-10000Hz\n"
     ]
    }
   ],
   "source": [
    "# === JUPYTER CELL: Full pipeline with frequency-range and band-diversity knobs ===\n",
    "import json, math, random, copy\n",
    "import numpy as np, pandas as pd\n",
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# -----------------------\n",
    "# PATHS \n",
    "# -----------------------\n",
    "MODEL_PATH   = \"/Users/hosseinostovar/Desktop/BACKUP/Data_H2SO4_NPG/data/single_frequency/Single_frequencies_whole_spectrum/PINN_report/pinn_model.pt\"\n",
    "DATA_ALL     = \"/Users/hosseinostovar/Desktop/BACKUP/Data_H2SO4_NPG/data/single_frequency/Single_frequencies_whole_spectrum/PINN_report/compiled_dataset.csv\"        # full spectra table (train+test)\n",
    "DATA_TEST    = \"/Users/hosseinostovar/Desktop/BACKUP/Data_H2SO4_NPG/data/single_frequency/Single_frequencies_whole_spectrum/PINN_report/test_predictions_pinn.csv\"   # held-out test spectra (per-frequency rows)\n",
    "OUT_DIR      = Path(\"/Users/hosseinostovar/Desktop/BACKUP/Data_H2SO4_NPG/data/single_frequency/Single_frequencies_whole_spectrum/inverse_reports/operando_piplines/high_f_1000-10000Hz\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "(OUT_DIR/\"plots\").mkdir(exist_ok=True)\n",
    "\n",
    "# Targets\n",
    "TARGET_C_MAE = 0.2   # mM\n",
    "TARGET_T_MAE = 0.5   # °C\n",
    "\n",
    "# Bounds (training domain)\n",
    "C_MIN, C_MAX = 5.0, 20.0\n",
    "T_MIN, T_MAX = 26.0, 50.0\n",
    "\n",
    "# Candidate K values to try for top-K frequency sets\n",
    "K_LIST = [1, 3, 6, 10]\n",
    "TEST_ALL_K = True   # set False to keep \"best only\" behavior\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Frequency selection knobs (NEW)\n",
    "# -----------------------\n",
    "# A) Allow only specific frequency windows; leave [] for whole range\n",
    "#    Example to avoid sub-Hz entirely: ALLOWED_WINDOWS = [(1.0, 1e4)]\n",
    "ALLOWED_WINDOWS = []   # [] => no restriction\n",
    "\n",
    "# B) Enforce band-diversity quotas (round-robin pick). Leave [] to disable.\n",
    "#    Example: one subHz, one 1–100, one 100–1000, one 1k–10k; remainder auto-filled.\n",
    "BANDS = [\n",
    "    {\"name\":\"subHz\",  \"min\":0.0,   \"max\":1.0,    \"quota\":0},\n",
    "    {\"name\":\"1_100\",  \"min\":1.0,   \"max\":100.0,  \"quota\":0},\n",
    "    {\"name\":\"100_1k\", \"min\":100.0, \"max\":1000.0, \"quota\":0},\n",
    "    {\"name\":\"1k_10k\", \"min\":1000.0,\"max\":1e4,    \"quota\":20},\n",
    "]\n",
    "\n",
    "# -----------------------\n",
    "# Forward physics (same as your training)\n",
    "# -----------------------\n",
    "def _j_like(x):\n",
    "    return torch.complex(torch.zeros((), dtype=x.dtype, device=x.device),\n",
    "                         torch.ones( (), dtype=x.dtype, device=x.device))\n",
    "\n",
    "def torch_coth(z, eps=1e-12):\n",
    "    sz = torch.sinh(z); cz = torch.cosh(z)\n",
    "    small = torch.abs(sz) < eps\n",
    "    out = torch.empty_like(z)\n",
    "    out[~small] = cz[~small] / sz[~small]\n",
    "    out[small] = 1.0/z[small] + z[small]/3.0\n",
    "    return out\n",
    "\n",
    "def torch_zarc(Rp, Y0, n, w):\n",
    "    j = _j_like(w)\n",
    "    return 1.0 / (1.0/torch.clamp(Rp, min=1e-18) + torch.clamp(Y0, min=1e-18) * (j*w)**n)\n",
    "\n",
    "def torch_tl_impedance(r, y0, n, L, w):\n",
    "    j = _j_like(w)\n",
    "    r_ = torch.clamp(r,  min=1e-18); y0_= torch.clamp(y0, min=1e-18)\n",
    "    gamma = torch.sqrt(r_ * y0_ * (j*w)**n)\n",
    "    Z0    = torch.sqrt(r_ / (y0_ * (j*w)**n))\n",
    "    return Z0 * torch_coth(L * gamma)\n",
    "\n",
    "def torch_impedance_rs_zarc_tl(omega, Rs, Rp, Y0, n0, r, y0, n1, L):\n",
    "    Zarc = torch_zarc(Rp, Y0, n0, omega)\n",
    "    Ztl  = torch_tl_impedance(r, y0, n1, L, omega)\n",
    "    return Rs + Zarc + Ztl\n",
    "\n",
    "class ThetaNet(nn.Module):\n",
    "    def __init__(self, in_dim=2, width=64, depth=3, dtype=torch.float64):\n",
    "        super().__init__()\n",
    "        layers, d = [], in_dim\n",
    "        for _ in range(depth):\n",
    "            layers += [nn.Linear(d, width, dtype=dtype), nn.ReLU()]\n",
    "            d = width\n",
    "        self.backbone = nn.Sequential(*layers) if layers else nn.Identity()\n",
    "        self.head = nn.Linear(d, 8, dtype=dtype)  # Rs, Rp, Y0, n0, r, y0, n1, L\n",
    "        self.softplus = nn.Softplus(); self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, Cn, Tn):\n",
    "        h = self.backbone(torch.stack([Cn, Tn], dim=1))\n",
    "        raw = self.head(h)\n",
    "        Rs_r, Rp_r, Y0_r, n0_r, r_r, y0_r, n1_r, L_r = torch.unbind(raw, dim=1)\n",
    "        eps = 1e-9\n",
    "        Rs  = self.softplus(Rs_r)  + eps\n",
    "        Rp  = self.softplus(Rp_r)  + eps\n",
    "        Y0  = self.softplus(Y0_r)  + eps\n",
    "        n0  = self.sigmoid(n0_r)\n",
    "        r   = self.softplus(r_r)   + eps\n",
    "        y0  = self.softplus(y0_r)  + eps\n",
    "        n1  = self.sigmoid(n1_r)\n",
    "        L   = self.softplus(L_r)   + eps\n",
    "        return Rs, Rp, Y0, n0, r, y0, n1, L\n",
    "\n",
    "class PINNForward:\n",
    "    def __init__(self, model_path, device=\"cpu\"):\n",
    "        # Support PyTorch 2.6+ change in default weights_only\n",
    "        try:\n",
    "            ckpt = torch.load(model_path, map_location=device, weights_only=False)\n",
    "        except TypeError:\n",
    "            ckpt = torch.load(model_path, map_location=device)\n",
    "        self.xmu  = np.array(ckpt.get(\"xmu\",  [0,0]), float)\n",
    "        self.xstd = np.array(ckpt.get(\"xstd\", [1,1]), float)\n",
    "        tr = ckpt.get(\"train_config\", {})\n",
    "        width = int(tr.get(\"width\", 64)); depth = int(tr.get(\"depth\", 3))\n",
    "        self.net = ThetaNet(in_dim=2, width=width, depth=depth, dtype=torch.float64).to(device)\n",
    "        self.net.load_state_dict(ckpt[\"state_dict\"])\n",
    "        self.net.eval()\n",
    "        self.device = torch.device(device)\n",
    "        self.y_norm = ckpt.get(\"y_norm\", {\"enabled\": False})\n",
    "        self._dtype = torch.float64\n",
    "    def predict_torch(self, C_t, T_t, w_t):\n",
    "        Cn = (C_t - float(self.xmu[0])) / (float(self.xstd[0]) + 1e-12)\n",
    "        Tn = (T_t - float(self.xmu[1])) / (float(self.xstd[1]) + 1e-12)\n",
    "        Rs,Rp,Y0,n0,r,y0,n1,L = self.net(Cn, Tn)\n",
    "        Zc = torch_impedance_rs_zarc_tl(w_t, Rs,Rp,Y0,n0,r,y0,n1,L)\n",
    "        y = torch.stack([Zc.real, -Zc.imag], dim=1)  # [Z', -Z'']\n",
    "        yn = self.y_norm\n",
    "        if yn.get(\"enabled\", False):\n",
    "            method = yn.get(\"method\",\"standard\")\n",
    "            if method == \"standard\":\n",
    "                mu  = torch.tensor(yn[\"mu\"],  dtype=self._dtype, device=self.device)\n",
    "                std = torch.tensor(yn[\"std\"], dtype=self._dtype, device=self.device)\n",
    "                y = y*std + mu\n",
    "            elif method == \"minmax\":\n",
    "                y_min = torch.tensor(yn[\"min\"], dtype=self._dtype, device=self.device)\n",
    "                y_max = torch.tensor(yn[\"max\"], dtype=self._dtype, device=self.device)\n",
    "                y = y*(y_max - y_min) + y_min\n",
    "        return y\n",
    "\n",
    "# -----------------------\n",
    "# Helpers: grouping spectra\n",
    "# -----------------------\n",
    "def norm_col(df, names, fallback=None):\n",
    "    low = {c.lower(): c for c in df.columns}\n",
    "    for n in names:\n",
    "        if n.lower() in low: return low[n.lower()]\n",
    "    return fallback\n",
    "\n",
    "def read_full_dataset(path):\n",
    "    df = pd.read_csv(path)\n",
    "    fcol  = norm_col(df, [\"frequency_Hz\",\"frequency (Hz)\",\"freq (hz)\",\"f (hz)\",\"f\",\"f_hz\"], None)\n",
    "    zrcol = norm_col(df, [\"Z_real\",\"Z' (Ω)\",\"z_real\",\"zre\",\"re(z)\"], None)\n",
    "    zinc  = norm_col(df, [\"Z_imag_neg\",\"-Z'' (Ω)\",\"-z_imag\",\"-imag\",\"-zim\"], None)\n",
    "    if fcol is None or zrcol is None or zinc is None:\n",
    "        raise RuntimeError(\"Could not resolve frequency/Z columns in compiled_dataset.csv\")\n",
    "    ccol = norm_col(df, [\"concentration_mM\",\"concentration (mm)\",\"conc_mm\",\"c_mm\"], \"concentration_mM\")\n",
    "    tcol = norm_col(df, [\"temperature_C\",\"temp_c\",\"t_c\"], \"temperature_C\")\n",
    "    scol = norm_col(df, [\"source_file\",\"file\",\"path\"], \"source_file\")\n",
    "    keep = [\"frequency_Hz\",\"Z_real\",\"Z_imag_neg\", ccol, tcol, scol]\n",
    "    tmp = df[[fcol, zrcol, zinc, ccol, tcol, scol]].copy()\n",
    "    tmp.columns = keep\n",
    "    tmp = tmp.dropna(subset=[\"frequency_Hz\",\"Z_real\",\"Z_imag_neg\"]).reset_index(drop=True)\n",
    "    return tmp\n",
    "\n",
    "def group_by_CT(df):\n",
    "    groups = []\n",
    "    for (c,t), sub in df.groupby([\"concentration_mM\",\"temperature_C\"]):\n",
    "        sub = sub.sort_values(\"frequency_Hz\")\n",
    "        groups.append({\"id\": f\"C{float(c):g}_T{float(t):g}\",\n",
    "                       \"C\": float(c), \"T\": float(t),\n",
    "                       \"f\": sub[\"frequency_Hz\"].astype(float).to_numpy(),\n",
    "                       \"Zr\": sub[\"Z_real\"].astype(float).to_numpy(),\n",
    "                       \"Zim_neg\": sub[\"Z_imag_neg\"].astype(float).to_numpy()})\n",
    "    return groups\n",
    "\n",
    "# -----------------------\n",
    "# Inverse solver (ALL freqs or subset)\n",
    "# -----------------------\n",
    "def sigmoid_to_range(x, lo, hi): return lo + (hi - lo) * torch.sigmoid(x)\n",
    "\n",
    "def init_raw_from_guess(c0, t0, lo_c, hi_c, lo_t, hi_t):\n",
    "    eps = 1e-6\n",
    "    c0 = float(np.clip(c0, lo_c+eps, hi_c-eps)); t0 = float(np.clip(t0, lo_t+eps, hi_t-eps))\n",
    "    invsig = lambda y, lo, hi: math.log((y-lo)/(hi-y))\n",
    "    return torch.tensor([invsig(c0, lo_c, hi_c), invsig(t0, lo_t, hi_t)], dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "def invert_spectrum(forward, f, zr, zim_neg,\n",
    "                    lo_c=C_MIN, hi_c=C_MAX, lo_t=T_MIN, hi_t=T_MAX,\n",
    "                    restarts=10, steps_adam=300, steps_lbfgs=80,\n",
    "                    wr=1.0, wi=1.0):\n",
    "    device = forward.device\n",
    "    f = np.asarray(f, float); zr = np.asarray(zr, float); zi = -np.asarray(zim_neg, float)\n",
    "    if f.size == 0:\n",
    "        return {\"C\": np.nan, \"T\": np.nan, \"loss\": np.nan, \"se_C\": np.nan, \"se_T\": np.nan}\n",
    "    w = torch.tensor(2*np.pi*f, dtype=torch.float64, device=device)\n",
    "    zr_t = torch.tensor(zr, dtype=torch.float64, device=device)\n",
    "    zi_t = torch.tensor(zi, dtype=torch.float64, device=device)\n",
    "    def loss_from(raw):\n",
    "        C = sigmoid_to_range(raw[0], lo_c, hi_c)\n",
    "        T = sigmoid_to_range(raw[1], lo_t, hi_t)\n",
    "        y = forward.predict_torch(C.repeat(w.numel()), T.repeat(w.numel()), w)\n",
    "        yzr, yzi = y[:,0], -y[:,1]\n",
    "        sr = torch.clamp(zr_t.abs().median(), min=1e-9)\n",
    "        si = torch.clamp(zi_t.abs().median(), min=1e-9)\n",
    "        return wr*torch.mean(((yzr - zr_t)/sr)**2) + wi*torch.mean(((yzi - zi_t)/si)**2)\n",
    "    best = {\"loss\": float(\"inf\")}\n",
    "    # multi-start: small grid + random\n",
    "    grid_c = np.linspace(lo_c, hi_c, max(2, int(math.sqrt(restarts))))\n",
    "    grid_t = np.linspace(lo_t, hi_t, max(2, int(math.sqrt(restarts))))\n",
    "    seeds = [(float(c), float(t)) for c in grid_c for t in grid_t]\n",
    "    while len(seeds) < restarts:\n",
    "        seeds.append((random.uniform(lo_c, hi_c), random.uniform(lo_t, hi_t)))\n",
    "    for c0,t0 in seeds[:restarts]:\n",
    "        raw = init_raw_from_guess(c0, t0, lo_c, hi_c, lo_t, hi_t).to(device)\n",
    "        # Adam\n",
    "        opt = optim.Adam([raw], lr=0.08)\n",
    "        for _ in range(steps_adam):\n",
    "            opt.zero_grad(); L = loss_from(raw); L.backward(); opt.step()\n",
    "        # LBFGS\n",
    "        def closure():\n",
    "            opt2.zero_grad(); L2 = loss_from(raw); L2.backward(); return L2\n",
    "        opt2 = optim.LBFGS([raw], lr=1.0, max_iter=steps_lbfgs, line_search_fn=\"strong_wolfe\")\n",
    "        opt2.step(closure)\n",
    "        with torch.no_grad():\n",
    "            Lf = loss_from(raw).item()\n",
    "            Cf = float(sigmoid_to_range(raw[0], lo_c, hi_c).cpu().numpy())\n",
    "            Tf = float(sigmoid_to_range(raw[1], lo_t, hi_t).cpu().numpy())\n",
    "        if Lf < best[\"loss\"]:\n",
    "            best = {\"C\": Cf, \"T\": Tf, \"loss\": Lf, \"raw\": raw.detach().cpu().numpy()}\n",
    "    # crude SE via Gauss-Newton\n",
    "    try:\n",
    "        raw = torch.tensor(best[\"raw\"], dtype=torch.float64, device=device, requires_grad=True)\n",
    "        C = sigmoid_to_range(raw[0], lo_c, hi_c); T = sigmoid_to_range(raw[1], lo_t, hi_t)\n",
    "        y = forward.predict_torch(C.repeat(w.numel()), T.repeat(w.numel()), w)\n",
    "        yzr, yzi = y[:,0], -y[:,1]\n",
    "        sr = torch.clamp(zr_t.abs().median(), min=1e-9); si = torch.clamp(zi_t.abs().median(), min=1e-9)\n",
    "        res = torch.cat([(yzr - zr_t)/sr, (yzi - zi_t)/si], dim=0)\n",
    "        J = []\n",
    "        for i, var in enumerate([raw[0], raw[1]]):\n",
    "            g = torch.autograd.grad(res, var, retain_graph=(i==0), allow_unused=False)[0].view(-1,1)\n",
    "            J.append(g)\n",
    "        J = torch.cat(J, dim=1).detach().cpu().numpy()\n",
    "        JTJ = J.T @ J + 1e-10*np.eye(2)\n",
    "        cov = np.linalg.inv(JTJ)\n",
    "        rmse = float(torch.sqrt(torch.mean(res**2)).cpu().numpy())\n",
    "        se_raw = np.sqrt(np.diag(cov)) * rmse\n",
    "        s = 1/(1+np.exp(-best[\"raw\"]))\n",
    "        dC = s*(1-s)*(hi_c - lo_c); dT = s*(1-s)*(hi_t - lo_t)\n",
    "        best[\"se_C\"] = float(abs(dC[0])*se_raw[0]); best[\"se_T\"] = float(abs(dT[1])*se_raw[1])\n",
    "    except Exception:\n",
    "        best[\"se_C\"] = np.nan; best[\"se_T\"] = np.nan\n",
    "    return best\n",
    "\n",
    "# -----------------------\n",
    "# Load data & split into calibration vs test by (C,T)\n",
    "# -----------------------\n",
    "df_all  = read_full_dataset(DATA_ALL)\n",
    "df_test = pd.read_csv(DATA_TEST)  # has: frequency_Hz, Z_real_true, Z_imag_neg_true, concentration_mM, temperature_C\n",
    "\n",
    "# Normalize test column names\n",
    "need = {\"frequency_Hz\":\"frequency_Hz\",\"Z_real_true\":\"Z_real_true\",\"Z_imag_neg_true\":\"Z_imag_neg_true\",\n",
    "        \"concentration_mM\":\"concentration_mM\",\"temperature_C\":\"temperature_C\"}\n",
    "low = {c.lower(): c for c in df_test.columns}\n",
    "for k in list(need):\n",
    "    if k not in df_test.columns:\n",
    "        for c in list(low.values()):\n",
    "            if c.lower() == k.lower():\n",
    "                need[k] = c\n",
    "                break\n",
    "df_test = df_test.rename(columns={need[\"frequency_Hz\"]:\"frequency_Hz\",\n",
    "                                  need[\"Z_real_true\"]:\"Z_real_true\",\n",
    "                                  need[\"Z_imag_neg_true\"]:\"Z_imag_neg_true\",\n",
    "                                  need[\"concentration_mM\"]:\"concentration_mM\",\n",
    "                                  need[\"temperature_C\"]:\"temperature_C\"})\n",
    "\n",
    "# Build test spectra (true Z from file)\n",
    "test_groups = []\n",
    "for (c,t), sub in df_test.groupby([\"concentration_mM\",\"temperature_C\"]):\n",
    "    sub = sub.sort_values(\"frequency_Hz\")\n",
    "    test_groups.append({\n",
    "        \"id\": f\"C{float(c):g}_T{float(t):g}\",\n",
    "        \"C\": float(c), \"T\": float(t),\n",
    "        \"f\": sub[\"frequency_Hz\"].astype(float).to_numpy(),\n",
    "        \"Zr\": sub[\"Z_real_true\"].astype(float).to_numpy(),\n",
    "        \"Zim_neg\": sub[\"Z_imag_neg_true\"].astype(float).to_numpy()\n",
    "    })\n",
    "test_CT = {(g[\"C\"], g[\"T\"]) for g in test_groups}\n",
    "\n",
    "# Calibration = everything in compiled_dataset that is NOT in the test (by (C,T))\n",
    "cal_df = df_all[~df_all.set_index([\"concentration_mM\",\"temperature_C\"]).index.isin(test_CT)].copy()\n",
    "cal_groups = group_by_CT(cal_df)\n",
    "\n",
    "# Also capture the master frequency grid from data\n",
    "FREQS_ALL = np.sort(df_all[\"frequency_Hz\"].unique())\n",
    "Path(OUT_DIR/\"_meta.json\").write_text(json.dumps({\n",
    "    \"n_calib_spectra\": len(cal_groups),\n",
    "    \"n_test_spectra\":  len(test_groups),\n",
    "    \"n_unique_freqs\":  int(len(FREQS_ALL)),\n",
    "    \"freqs_min_max\":   [float(FREQS_ALL.min()), float(FREQS_ALL.max())]\n",
    "}, indent=2))\n",
    "\n",
    "# -----------------------\n",
    "# Frequency ranking by sensitivity (fast)\n",
    "# -----------------------\n",
    "DEV  = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "fwd  = PINNForward(MODEL_PATH, device=DEV)\n",
    "\n",
    "def jacobian_scores(Cval, Tval, freqs):\n",
    "    device = fwd.device\n",
    "    w = torch.tensor(2*np.pi*freqs, dtype=torch.float64, device=device)\n",
    "    C = torch.tensor(Cval, dtype=torch.float64, device=device, requires_grad=True)\n",
    "    T = torch.tensor(Tval, dtype=torch.float64, device=device, requires_grad=True)\n",
    "    y = fwd.predict_torch(C.repeat(w.numel()), T.repeat(w.numel()), w)\n",
    "    Zr = y[:,0]; Zim = -y[:,1]\n",
    "    rows=[]\n",
    "    for i in range(len(freqs)):\n",
    "        gC = torch.stack([torch.autograd.grad(Zr[i],C,retain_graph=True)[0],\n",
    "                          torch.autograd.grad(Zim[i],C,retain_graph=True)[0]])\n",
    "        gT = torch.stack([torch.autograd.grad(Zr[i],T,retain_graph=True)[0],\n",
    "                          torch.autograd.grad(Zim[i],T,retain_graph=True)[0]])\n",
    "        J  = torch.stack([gC,gT], dim=1).detach().cpu().numpy()  # 2x2\n",
    "        JTJ = J.T @ J\n",
    "        det = float(np.linalg.det(JTJ))\n",
    "        # min eigenvalue helps conditioning; angle helps C vs T separation\n",
    "        eigs = np.linalg.eigvalsh(JTJ)\n",
    "        emin = float(np.min(eigs))\n",
    "        c1, c2 = J[:,0], J[:,1]\n",
    "        n1, n2 = np.linalg.norm(c1), np.linalg.norm(c2)\n",
    "        angle = float(np.degrees(np.arccos(np.clip(np.dot(c1,c2)/(max(n1,1e-12)*max(n2,1e-12)),-1,1)))) if n1>0 and n2>0 else 0.0\n",
    "        rows.append({\"f\": float(freqs[i]), \"D\": det, \"E\": emin, \"angle\": angle})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Score on a coarse grid of (C,T) to avoid biasing with test\n",
    "C_grid = np.linspace(C_MIN, C_MAX, 6)\n",
    "T_grid = np.linspace(T_MIN, T_MAX, 6)\n",
    "blocks=[]\n",
    "with tqdm(total=len(C_grid)*len(T_grid), desc=\"Sensitivity sweep (ranking)\") as pbar:\n",
    "    for C0 in C_grid:\n",
    "        for T0 in T_grid:\n",
    "            blocks.append(jacobian_scores(C0, T0, FREQS_ALL))\n",
    "            pbar.update(1)\n",
    "rank_df = pd.concat(blocks, ignore_index=True)\n",
    "global_rank = (rank_df.groupby(\"f\", as_index=False)\n",
    "               .agg(D_mean=(\"D\",\"mean\"), E_mean=(\"E\",\"mean\"), angle_mean=(\"angle\",\"mean\"))\n",
    "               .sort_values([\"D_mean\",\"E_mean\",\"angle_mean\"], ascending=[False,False,False])\n",
    "               .reset_index(drop=True))\n",
    "global_rank.to_csv(OUT_DIR/\"global_frequency_ranking.csv\", index=False)\n",
    "\n",
    "# -----------------------\n",
    "# Constrained frequency selection (NEW)\n",
    "# -----------------------\n",
    "def _apply_windows(df_rank, windows):\n",
    "    if not windows: \n",
    "        return df_rank.copy()\n",
    "    mask = np.zeros(len(df_rank), dtype=bool)\n",
    "    fvals = df_rank[\"f\"].values\n",
    "    for (lo, hi) in windows:\n",
    "        mask |= (fvals >= float(lo)) & (fvals <= float(hi))\n",
    "    out = df_rank.loc[mask].reset_index(drop=True)\n",
    "    return out\n",
    "\n",
    "def _apply_bands_pick(df_rank, K, bands):\n",
    "    \"\"\"\n",
    "    Round-robin pick under band quotas (highest-ranked per band).\n",
    "    If quotas don't fill K, remaining slots are filled by overall ranking among unused.\n",
    "    \"\"\"\n",
    "    if not bands:\n",
    "        return df_rank.head(K)[\"f\"].to_numpy()\n",
    "\n",
    "    bands_local = copy.deepcopy(bands)  # don't mutate user quotas\n",
    "    per = []\n",
    "    used = set()\n",
    "    for b in bands_local:\n",
    "        sub = df_rank[(df_rank[\"f\"] >= float(b[\"min\"])) & (df_rank[\"f\"] <= float(b[\"max\"]))].copy().reset_index(drop=True)\n",
    "        per.append({\"band\": b, \"freqs\": sub[\"f\"].tolist(), \"i\": 0})\n",
    "\n",
    "    picked = []\n",
    "    # First pass: honor quotas in round-robin\n",
    "    while len(picked) < K and any(p[\"i\"] < len(p[\"freqs\"]) and p[\"band\"][\"quota\"] > 0 for p in per):\n",
    "        for p in per:\n",
    "            if len(picked) >= K:\n",
    "                break\n",
    "            q = p[\"band\"][\"quota\"]\n",
    "            # advance to next unused freq in this band\n",
    "            while p[\"i\"] < len(p[\"freqs\"]) and p[\"freqs\"][p[\"i\"]] in used:\n",
    "                p[\"i\"] += 1\n",
    "            if q > 0 and p[\"i\"] < len(p[\"freqs\"]):\n",
    "                f = p[\"freqs\"][p[\"i\"]]\n",
    "                picked.append(f); used.add(f)\n",
    "                p[\"band\"][\"quota\"] = q - 1\n",
    "                p[\"i\"] += 1\n",
    "\n",
    "    # Second pass: fill remaining from overall rank among unused\n",
    "    if len(picked) < K:\n",
    "        for f in df_rank[\"f\"].tolist():\n",
    "            if f not in used:\n",
    "                picked.append(f); used.add(f)\n",
    "            if len(picked) >= K:\n",
    "                break\n",
    "\n",
    "    return np.array(picked[:K], float)\n",
    "\n",
    "def choose_frequencies(global_rank, K, windows=None, bands=None, out_json_path=None):\n",
    "    # 1) filter by windows (if any)\n",
    "    rank2 = _apply_windows(global_rank, windows or [])\n",
    "    if rank2.empty:\n",
    "        raise RuntimeError(\"No candidate frequencies remain after applying ALLOWED_WINDOWS.\")\n",
    "    # 2) band quotas (if any), else top-K\n",
    "    freqs = _apply_bands_pick(rank2, K, bands or []) if (bands and len(bands)>0) else rank2.head(K)[\"f\"].to_numpy()\n",
    "    # optional: save selection reasoning\n",
    "    if out_json_path:\n",
    "        Path(out_json_path).write_text(json.dumps({\n",
    "            \"K\": int(K),\n",
    "            \"windows\": windows or [],\n",
    "            \"bands\": bands or [],\n",
    "            \"picked_Hz\": list(map(float, freqs)),\n",
    "            \"n_candidates_after_windows\": int(len(rank2))\n",
    "        }, indent=2))\n",
    "    return freqs\n",
    "\n",
    "# -----------------------\n",
    "# Helper: evaluate inverse MAE on a set of spectra using a selected freq set\n",
    "# -----------------------\n",
    "def eval_inverse_on_groups(groups, freq_set, desc=\"eval\"):\n",
    "    rows=[]\n",
    "    with tqdm(groups, desc=desc) as pbar:\n",
    "        for g in pbar:\n",
    "            m = np.isin(g[\"f\"], freq_set)\n",
    "            f  = g[\"f\"][m]; Zr = g[\"Zr\"][m]; Zin = g[\"Zim_neg\"][m]\n",
    "            res = invert_spectrum(fwd, f, Zr, Zin)\n",
    "            rows.append({\"id\": g[\"id\"], \"C_true\": g[\"C\"], \"T_true\": g[\"T\"],\n",
    "                         \"C_pred\": res[\"C\"], \"T_pred\": res[\"T\"],\n",
    "                         \"C_err\": (res[\"C\"]-g[\"C\"]) if np.isfinite(res[\"C\"]) else np.nan,\n",
    "                         \"T_err\": (res[\"T\"]-g[\"T\"]) if np.isfinite(res[\"T\"]) else np.nan,\n",
    "                         \"n_freq\": int(len(f)), \"loss\": res[\"loss\"],\n",
    "                         \"se_C\": res.get(\"se_C\", np.nan), \"se_T\": res.get(\"se_T\", np.nan)})\n",
    "    df = pd.DataFrame(rows)\n",
    "    def mae(a): \n",
    "        a = np.asarray(a, float)\n",
    "        return float(np.nanmean(np.abs(a))) if np.isfinite(a).any() else np.nan\n",
    "    metrics = {\"N\": int(len(df)), \"C_MAE\": mae(df[\"C_err\"]), \"T_MAE\": mae(df[\"T_err\"])}\n",
    "    return df, metrics\n",
    "\n",
    "# -----------------------\n",
    "# 1) Choose minimal K meeting targets on CALIBRATION\n",
    "# -----------------------\n",
    "best_choice = None\n",
    "cal_results = []\n",
    "for K in K_LIST:\n",
    "    topK = choose_frequencies(\n",
    "        global_rank, K,\n",
    "        windows=ALLOWED_WINDOWS,   # [] ⇒ whole range\n",
    "        bands=BANDS,               # [] ⇒ no band quotas\n",
    "        out_json_path=OUT_DIR/f\"selection_debug_top{K}.json\"\n",
    "    )\n",
    "    df_cal, m_cal = eval_inverse_on_groups(cal_groups, topK, desc=f\"Calibration inverse @ top-{K}\")\n",
    "    m_cal[\"K\"] = K\n",
    "    cal_results.append(m_cal)\n",
    "    df_cal.to_csv(OUT_DIR/f\"calibration_inverse_top{K}.csv\", index=False)\n",
    "    Path(OUT_DIR/f\"calibration_metrics_top{K}.json\").write_text(json.dumps(m_cal, indent=2))\n",
    "    if (m_cal[\"C_MAE\"] <= TARGET_C_MAE) and (m_cal[\"T_MAE\"] <= TARGET_T_MAE) and (best_choice is None):\n",
    "        best_choice = {\"K\": K, \"freqs\": topK, \"cal_metrics\": m_cal}\n",
    "\n",
    "if best_choice is None:\n",
    "    # pick the best trade-off (minimize weighted sum)\n",
    "    scores = [(m[\"C_MAE\"]/TARGET_C_MAE + m[\"T_MAE\"]/TARGET_T_MAE, m[\"K\"]) for m in cal_results]\n",
    "    scores.sort()\n",
    "    bestK = scores[0][1]\n",
    "    best_choice = {\"K\": bestK,\n",
    "                   \"freqs\": choose_frequencies(global_rank, bestK, windows=ALLOWED_WINDOWS, bands=BANDS),\n",
    "                   \"cal_metrics\": [m for m in cal_results if m[\"K\"]==bestK][0]}\n",
    "\n",
    "Path(OUT_DIR/\"chosen_frequency_set.json\").write_text(json.dumps({\n",
    "    \"K\": int(best_choice[\"K\"]), \"freqs_Hz\": list(map(float, best_choice[\"freqs\"])),\n",
    "    \"targets\": {\"C_MAE_mM\": TARGET_C_MAE, \"T_MAE_C\": TARGET_T_MAE},\n",
    "    \"calibration_metrics\": best_choice[\"cal_metrics\"],\n",
    "    \"windows\": ALLOWED_WINDOWS,\n",
    "    \"bands\": BANDS\n",
    "}, indent=2))\n",
    "\n",
    "# -----------------------\n",
    "# 2) Lock the chosen set and evaluate on TEST (held-out)\n",
    "# -----------------------\n",
    "# -----------------------\n",
    "# 2) Evaluate on TEST (held-out)\n",
    "# -----------------------\n",
    "test_summ_rows = []\n",
    "\n",
    "if TEST_ALL_K:\n",
    "    # Evaluate test for every K in K_LIST (under same window/band constraints)\n",
    "    for K in K_LIST:\n",
    "        selK = choose_frequencies(\n",
    "            global_rank, K,\n",
    "            windows=ALLOWED_WINDOWS,\n",
    "            bands=BANDS,\n",
    "            out_json_path=OUT_DIR/f\"selection_debug_TEST_top{K}.json\"\n",
    "        )\n",
    "        df_test_invK, m_testK = eval_inverse_on_groups(test_groups, selK, desc=f\"TEST inverse @ top-{K}\")\n",
    "        df_test_invK.to_csv(OUT_DIR/f\"test_inverse_predictions_top{K}.csv\", index=False)\n",
    "        Path(OUT_DIR/f\"test_inverse_metrics_top{K}.json\").write_text(json.dumps({\n",
    "            \"K\": int(K), \"C_MAE_mM\": m_testK[\"C_MAE\"], \"T_MAE_C\": m_testK[\"T_MAE\"], \"N\": m_testK[\"N\"]\n",
    "        }, indent=2))\n",
    "        test_summ_rows.append({\"K\": int(K), \"C_MAE_mM\": m_testK[\"C_MAE\"], \"T_MAE_C\": m_testK[\"T_MAE\"], \"N\": m_testK[\"N\"]})\n",
    "\n",
    "    # Save a compact summary over all K\n",
    "    pd.DataFrame(test_summ_rows).sort_values(\"K\").to_csv(OUT_DIR/\"test_inverse_metrics_summary.csv\", index=False)\n",
    "\n",
    "    # Also keep the “best” K products to preserve your current UX\n",
    "    freq_set = best_choice[\"freqs\"]\n",
    "    df_test_inv, m_test = eval_inverse_on_groups(test_groups, freq_set, desc=f\"TEST inverse @ top-{best_choice['K']}\")\n",
    "    df_test_inv.to_csv(OUT_DIR/\"test_inverse_predictions_bestK.csv\", index=False)\n",
    "    Path(OUT_DIR/\"test_inverse_metrics_bestK.json\").write_text(json.dumps({\n",
    "        \"K\": int(best_choice[\"K\"]), \"C_MAE_mM\": m_test[\"C_MAE\"], \"T_MAE_C\": m_test[\"T_MAE\"], \"N\": m_test[\"N\"]\n",
    "    }, indent=2))\n",
    "\n",
    "else:\n",
    "    # Original behavior: only the best K\n",
    "    freq_set = best_choice[\"freqs\"]\n",
    "    df_test_inv, m_test = eval_inverse_on_groups(test_groups, freq_set, desc=f\"TEST inverse @ top-{best_choice['K']}\")\n",
    "    df_test_inv.to_csv(OUT_DIR/\"test_inverse_predictions.csv\", index=False)\n",
    "    Path(OUT_DIR/\"test_inverse_metrics.json\").write_text(json.dumps({\n",
    "        \"K\": int(best_choice[\"K\"]), \"C_MAE_mM\": m_test[\"C_MAE\"], \"T_MAE_C\": m_test[\"T_MAE\"], \"N\": m_test[\"N\"]\n",
    "    }, indent=2))\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 3) Bar plots (True vs Pred) on TEST\n",
    "# -----------------------\n",
    "if TEST_ALL_K:\n",
    "    for K in K_LIST:\n",
    "        dfK_path = OUT_DIR/f\"test_inverse_predictions_top{K}.csv\"\n",
    "        if not Path(dfK_path).exists(): \n",
    "            continue\n",
    "        dfK = pd.read_csv(dfK_path)\n",
    "        labels = dfK[\"id\"].tolist()\n",
    "        x = np.arange(len(labels)); width = 0.38\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(max(10, 0.4*len(labels)), 5))\n",
    "        ax.bar(x - width/2, dfK[\"C_true\"], width, label=\"True C\")\n",
    "        ax.bar(x + width/2, dfK[\"C_pred\"], width, label=\"Pred C\")\n",
    "        ax.set_xticks(x); ax.set_xticklabels(labels, rotation=45, ha=\"right\")\n",
    "        ax.set_ylabel(\"mM\"); ax.set_title(f\"TEST — True vs Pred C (top-{K} freqs)\")\n",
    "        ax.legend(); plt.tight_layout()\n",
    "        plt.savefig(OUT_DIR/f\"plots/bar_true_vs_pred_C_top{K}.png\", dpi=180); plt.close(fig)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(max(10, 0.4*len(labels)), 5))\n",
    "        ax.bar(x - width/2, dfK[\"T_true\"], width, label=\"True T\")\n",
    "        ax.bar(x + width/2, dfK[\"T_pred\"], width, label=\"Pred T\")\n",
    "        ax.set_xticks(x); ax.set_xticklabels(labels, rotation=45, ha=\"right\")\n",
    "        ax.set_ylabel(\"°C\"); ax.set_title(f\"TEST — True vs Pred T (top-{K} freqs)\")\n",
    "        ax.legend(); plt.tight_layout()\n",
    "        plt.savefig(OUT_DIR/f\"plots/bar_true_vs_pred_T_top{K}.png\", dpi=180); plt.close(fig)\n",
    "else:\n",
    "    labels = df_test_inv[\"id\"].tolist()\n",
    "    x = np.arange(len(labels)); width = 0.38\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(max(10, 0.4*len(labels)), 5))\n",
    "    ax.bar(x - width/2, df_test_inv[\"C_true\"], width, label=\"True C\")\n",
    "    ax.bar(x + width/2, df_test_inv[\"C_pred\"], width, label=\"Pred C\")\n",
    "    ax.set_xticks(x); ax.set_xticklabels(labels, rotation=45, ha=\"right\")\n",
    "    ax.set_ylabel(\"mM\"); ax.set_title(f\"TEST — True vs Pred C (top-{best_choice['K']} freqs)\")\n",
    "    ax.legend(); plt.tight_layout()\n",
    "    plt.savefig(OUT_DIR/\"plots/bar_true_vs_pred_C.png\", dpi=180); plt.close(fig)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(max(10, 0.4*len(labels)), 5))\n",
    "    ax.bar(x - width/2, df_test_inv[\"T_true\"], width, label=\"True T\")\n",
    "    ax.bar(x + width/2, df_test_inv[\"T_pred\"], width, label=\"Pred T\")\n",
    "    ax.set_xticks(x); ax.set_xticklabels(labels, rotation=45, ha=\"right\")\n",
    "    ax.set_ylabel(\"°C\"); ax.set_title(f\"TEST — True vs Pred T (top-{best_choice['K']} freqs)\")\n",
    "    ax.legend(); plt.tight_layout()\n",
    "    plt.savefig(OUT_DIR/\"plots/bar_true_vs_pred_T.png\", dpi=180); plt.close(fig)\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 4) Save a tiny runtime inverse module + config\n",
    "# -----------------------\n",
    "RUNTIME_PATH = OUT_DIR/\"ct_inverse_runtime.py\"\n",
    "RUNTIME_PATH.write_text(f\"\"\"\n",
    "import json, math, numpy as np, torch, torch.nn as nn, torch.optim as optim\n",
    "\n",
    "def _j_like(x):\n",
    "    return torch.complex(torch.zeros((), dtype=x.dtype, device=x.device),\n",
    "                         torch.ones( (), dtype=x.dtype, device=x.device))\n",
    "def torch_coth(z, eps=1e-12):\n",
    "    sz = torch.sinh(z); cz = torch.cosh(z)\n",
    "    small = torch.abs(sz) < eps\n",
    "    out = torch.empty_like(z)\n",
    "    out[~small] = cz[~small] / sz[~small]\n",
    "    out[small] = 1.0/z[small] + z[small]/3.0\n",
    "    return out\n",
    "def torch_zarc(Rp, Y0, n, w):\n",
    "    j = _j_like(w)\n",
    "    return 1.0 / (1.0/torch.clamp(Rp, min=1e-18) + torch.clamp(Y0, min=1e-18) * (j*w)**n)\n",
    "def torch_tl_impedance(r, y0, n, L, w):\n",
    "    j = _j_like(w)\n",
    "    r_ = torch.clamp(r,  min=1e-18); y0_= torch.clamp(y0, min=1e-18)\n",
    "    gamma = torch.sqrt(r_ * y0_ * (j*w)**n)\n",
    "    Z0    = torch.sqrt(r_ / (y0_ * (j*w)**n))\n",
    "    return Z0 * torch_coth(L * gamma)\n",
    "def torch_impedance_rs_zarc_tl(omega, Rs, Rp, Y0, n0, r, y0, n1, L):\n",
    "    Zarc = torch_zarc(Rp, Y0, n0, omega)\n",
    "    Ztl  = torch_tl_impedance(r, y0, n1, L, omega)\n",
    "    return Rs + Zarc + Ztl\n",
    "\n",
    "class ThetaNet(nn.Module):\n",
    "    def __init__(self, in_dim=2, width=64, depth=3, dtype=torch.float64):\n",
    "        super().__init__()\n",
    "        layers, d = [], in_dim\n",
    "        for _ in range(depth):\n",
    "            layers += [nn.Linear(d, width, dtype=dtype), nn.ReLU()]\n",
    "            d = width\n",
    "        self.backbone = nn.Sequential(*layers) if layers else nn.Identity()\n",
    "        self.head = nn.Linear(d, 8, dtype=dtype)\n",
    "        self.softplus = nn.Softplus(); self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, Cn, Tn):\n",
    "        h = self.backbone(torch.stack([Cn, Tn], dim=1))\n",
    "        raw = self.head(h)\n",
    "        Rs_r, Rp_r, Y0_r, n0_r, r_r, y0_r, n1_r, L_r = torch.unbind(raw, dim=1)\n",
    "        eps = 1e-9\n",
    "        Rs  = self.softplus(Rs_r)  + eps\n",
    "        Rp  = self.softplus(Rp_r)  + eps\n",
    "        Y0  = self.softplus(Y0_r)  + eps\n",
    "        n0  = self.sigmoid(n0_r)\n",
    "        r   = self.softplus(r_r)   + eps\n",
    "        y0  = self.softplus(y0_r)  + eps\n",
    "        n1  = self.sigmoid(n1_r)\n",
    "        L   = self.softplus(L_r)   + eps\n",
    "        return Rs, Rp, Y0, n0, r, y0, n1, L\n",
    "\n",
    "class ForwardPINN:\n",
    "    def __init__(self, model_path, device='cpu'):\n",
    "        try:\n",
    "            ckpt = torch.load(model_path, map_location=device, weights_only=False)\n",
    "        except TypeError:\n",
    "            ckpt = torch.load(model_path, map_location=device)\n",
    "        self.xmu  = np.array(ckpt.get('xmu',[0,0]), float)\n",
    "        self.xstd = np.array(ckpt.get('xstd',[1,1]), float)\n",
    "        tr = ckpt.get('train_config', {{}})\n",
    "        width = int(tr.get('width',64)); depth = int(tr.get('depth',3))\n",
    "        self.net = ThetaNet(in_dim=2, width=width, depth=depth, dtype=torch.float64).to(device)\n",
    "        self.net.load_state_dict(ckpt['state_dict']); self.net.eval()\n",
    "        self.device = torch.device(device)\n",
    "        self.y_norm = ckpt.get('y_norm', {{'enabled': False}})\n",
    "        self._dtype = torch.float64\n",
    "    def predict_torch(self, C_t, T_t, w_t):\n",
    "        Cn = (C_t - float(self.xmu[0])) / (float(self.xstd[0]) + 1e-12)\n",
    "        Tn = (T_t - float(self.xmu[1])) / (float(self.xstd[1]) + 1e-12)\n",
    "        Rs,Rp,Y0,n0,r,y0,n1,L = self.net(Cn, Tn)\n",
    "        Zc = torch_impedance_rs_zarc_tl(w_t, Rs,Rp,Y0,n0,r,y0,n1,L)\n",
    "        y = torch.stack([Zc.real, -Zc.imag], dim=1)\n",
    "        yn = self.y_norm\n",
    "        if yn.get('enabled', False):\n",
    "            method = yn.get('method','standard')\n",
    "            if method == 'standard':\n",
    "                mu  = torch.tensor(yn['mu'],  dtype=self._dtype, device=self.device)\n",
    "                std = torch.tensor(yn['std'], dtype=self._dtype, device=self.device)\n",
    "                y = y*std + mu\n",
    "            elif method == 'minmax':\n",
    "                y_min = torch.tensor(yn['min'], dtype=self._dtype, device=self.device)\n",
    "                y_max = torch.tensor(yn['max'], dtype=self._dtype, device=self.device)\n",
    "                y = y*(y_max - y_min) + y_min\n",
    "        return y\n",
    "\n",
    "def _sigmoid_to_range(x, lo, hi): return lo + (hi - lo) * torch.sigmoid(x)\n",
    "\n",
    "class CTInverseEstimator:\n",
    "    def __init__(self, model_path, chosen_freqs, c_bounds=({C_MIN}, {C_MAX}), t_bounds=({T_MIN}, {T_MAX}), device='cpu'):\n",
    "        self.forward = ForwardPINN(model_path, device=device)\n",
    "        self.freqs = np.array(chosen_freqs, float)\n",
    "        self.c_bounds = c_bounds; self.t_bounds = t_bounds\n",
    "    def estimate(self, freqs, Zr, Zim, restarts=8, steps_adam=250, steps_lbfgs=80, wr=1.0, wi=1.0):\n",
    "        freqs = np.asarray(freqs, float); Zr=np.asarray(Zr,float); Zim=np.asarray(Zim,float)\n",
    "        m = np.isin(freqs, self.freqs)\n",
    "        f = freqs[m]; zr = Zr[m]; zin = -Zim[m]  # convert to -Z'' convention internally\n",
    "        if len(f)==0: return {{'ok': False, 'reason':'no overlap with chosen frequencies'}}\n",
    "        device = self.forward.device\n",
    "        w = torch.tensor(2*np.pi*f, dtype=torch.float64, device=device)\n",
    "        zr_t = torch.tensor(zr, dtype=torch.float64, device=device)\n",
    "        zi_t = torch.tensor(zin, dtype=torch.float64, device=device)\n",
    "        lo_c,hi_c = self.c_bounds; lo_t,hi_t = self.t_bounds\n",
    "        def loss_from(raw):\n",
    "            C = _sigmoid_to_range(raw[0], lo_c, hi_c); T = _sigmoid_to_range(raw[1], lo_t, hi_t)\n",
    "            y = self.forward.predict_torch(C.repeat(w.numel()), T.repeat(w.numel()), w)\n",
    "            yzr, yzi = y[:,0], -y[:,1]\n",
    "            sr = torch.clamp(zr_t.abs().median(), min=1e-9)\n",
    "            si = torch.clamp(zi_t.abs().median(), min=1e-9)\n",
    "            return wr*torch.mean(((yzr - zr_t)/sr)**2) + wi*torch.mean(((yzi - zi_t)/si)**2)\n",
    "        def init_raw(c0,t0):\n",
    "            eps=1e-6\n",
    "            c0=float(np.clip(c0, lo_c+eps, hi_c-eps)); t0=float(np.clip(t0, lo_t+eps, hi_t-eps))\n",
    "            invsig=lambda y, lo, hi: math.log((y-lo)/(hi-y))\n",
    "            return torch.tensor([invsig(c0,lo_c,hi_c), invsig(t0,lo_t,hi_t)], dtype=torch.float64, requires_grad=True)\n",
    "        grid_c = np.linspace(lo_c, hi_c, max(2, int(math.sqrt(restarts))))\n",
    "        grid_t = np.linspace(lo_t, hi_t, max(2, int(math.sqrt(restarts))))\n",
    "        seeds = [(float(c),float(t)) for c in grid_c for t in grid_t]\n",
    "        while len(seeds)<restarts:\n",
    "            seeds.append((np.random.uniform(lo_c,hi_c), np.random.uniform(lo_t,hi_t)))\n",
    "        best={{'loss': float('inf')}}\n",
    "        for c0,t0 in seeds[:restarts]:\n",
    "            raw = init_raw(c0,t0).to(device)\n",
    "            opt = optim.Adam([raw], lr=0.08)\n",
    "            for _ in range(steps_adam):\n",
    "                opt.zero_grad(); L=loss_from(raw); L.backward(); opt.step()\n",
    "            def closure():\n",
    "                opt2.zero_grad(); L2=loss_from(raw); L2.backward(); return L2\n",
    "            opt2 = optim.LBFGS([raw], lr=1.0, max_iter=steps_lbfgs, line_search_fn='strong_wolfe')\n",
    "            opt2.step(closure)\n",
    "            with torch.no_grad():\n",
    "                Lf = loss_from(raw).item()\n",
    "                Cf = float(_sigmoid_to_range(raw[0], lo_c, hi_c).cpu().numpy())\n",
    "                Tf = float(_sigmoid_to_range(raw[1], lo_t, hi_t).cpu().numpy())\n",
    "            if Lf<best['loss']:\n",
    "                best={{'loss':Lf,'C_pred':Cf,'T_pred':Tf,'raw':raw.detach().cpu().numpy()}}\n",
    "        try:\n",
    "            raw = torch.tensor(best['raw'], dtype=torch.float64, device=device, requires_grad=True)\n",
    "            C=_sigmoid_to_range(raw[0], lo_c, hi_c); T=_sigmoid_to_range(raw[1], lo_t, hi_t)\n",
    "            y=self.forward.predict_torch(C.repeat(w.numel()), T.repeat(w.numel()), w)\n",
    "            yzr,yzi = y[:,0], -y[:,1]\n",
    "            sr=torch.clamp(zr_t.abs().median(),min=1e-9); si=torch.clamp(zi_t.abs().median(),min=1e-9)\n",
    "            res=torch.cat([(yzr-zr_t)/sr,(yzi-zi_t)/si],dim=0)\n",
    "            J=[]\n",
    "            for i,var in enumerate([raw[0],raw[1]]):\n",
    "                g=torch.autograd.grad(res,var,retain_graph=(i==0),allow_unused=False)[0].view(-1,1)\n",
    "                J.append(g)\n",
    "            J=np.concatenate([j.detach().cpu().numpy() for j in J],axis=1)\n",
    "            JTJ=J.T@J+1e-10*np.eye(2); cov=np.linalg.inv(JTJ)\n",
    "            rmse=float(torch.sqrt(torch.mean(res**2)).cpu().numpy())\n",
    "            se_raw=np.sqrt(np.diag(cov))*rmse\n",
    "            s=1/(1+np.exp(-best['raw'])); dC=s*(1-s)*(hi_c-lo_c); dT=s*(1-s)*(hi_t-lo_t)\n",
    "            seC=float(abs(dC[0])*se_raw[0]); seT=float(abs(dT[1])*se_raw[1])\n",
    "        except Exception:\n",
    "            seC=float('nan'); seT=float('nan')\n",
    "        return {{'ok': True, 'C_pred':best['C_pred'], 'T_pred':best['T_pred'],\n",
    "                 'se_C':seC, 'se_T':seT, 'used_freqs':list(map(float,f)),\n",
    "                 'loss':best['loss']}}\n",
    "\"\"\")\n",
    "\n",
    "# Save a tiny JSON config with the chosen freqs and bounds\n",
    "Path(OUT_DIR/\"ct_inverse_runtime_config.json\").write_text(json.dumps({\n",
    "    \"model_path\": MODEL_PATH,\n",
    "    \"chosen_freqs_Hz\": list(map(float, freq_set)),\n",
    "    \"C_bounds_mM\": [C_MIN, C_MAX],\n",
    "    \"T_bounds_C\":  [T_MIN, T_MAX],\n",
    "    \"windows\": ALLOWED_WINDOWS,\n",
    "    \"bands\": BANDS\n",
    "}, indent=2))\n",
    "\n",
    "print(\"\\n=== DONE ===\")\n",
    "print(\"Chosen frequency set (Hz):\", list(map(float, freq_set)))\n",
    "print(\"Calibration metrics:\", best_choice[\"cal_metrics\"])\n",
    "print(\"Test metrics:\", {\"C_MAE_mM\": m_test[\"C_MAE\"], \"T_MAE_C\": m_test[\"T_MAE\"]})\n",
    "print(\"Artifacts saved in:\", str(OUT_DIR))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
